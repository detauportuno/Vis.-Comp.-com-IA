{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G4HhD53B2rjV"
      },
      "source": [
        "# Trabalho #1 - Python com NumPy\n",
        "\n",
        "\n",
        "Este trabalho fornece uma breve revisão de Python. Mesmo que você já tenha usado Python, esse trabalho irá ajudar você a se familiarizar com as funções que precisaremos nessa disciplina.\n",
        "\n",
        "**Instruções:**\n",
        "- Você estará usando o Python 3.\n",
        "- Evite usar for-loops e while-loops, a menos que seja explicitamente instruído a fazê-lo.\n",
        "- As suas tarefas nesse trabalho estão sinalizadas nas células pelo comentário \"`# PARA VOCÊ FAZER:`\".\n",
        "- Depois de incluir o seu código, execute a célula modificada para verificar se o resultado está correto.\n",
        "\n",
        "**Após esse trabalho você irá:**\n",
        "- Ser capaz de usar os iPython Notebooks\n",
        "- Ser capaz de usar funções numpy e operações de tensores numpy\n",
        "- Compreender o conceito de \"broadcasting\"\n",
        "- Ser capaz de vetorizar um código\n",
        "\n",
        "(Esse trabalho é um adaptação de Adrew Ng, deeplearnig.ai)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PvSiPnKH2rjX"
      },
      "source": [
        "## Coloque os nomes e RAs dos alunos que fizeram esse trabalho\n",
        "\n",
        "Nome e número dos alunos da equipe:\n",
        "\n",
        "Aluno 1: Andre Pinho da Silva Sampaio RA: 20.00961-5\n",
        "\n",
        "Aluno 2: Christian Cunha Paes de Almeida RA: 20.01795-2\n",
        "\n",
        "Aluno 3 : Pedro Henrique Amendola Brandao RA: 20.01850-9"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iGpSrZO32rjY"
      },
      "source": [
        "## Sobre os notebooks iPython ##\n",
        "\n",
        "Os notebooks iPython são ambientes de codificação interativos incorporados em uma página da web. Você estará usando notebooks iPython nesta disciplina. Você só precisa escrever código entre os comentários `### COMEÇE AQUI ###` e `### TERMINE AQUI ###`. Depois de escrever seu código, você pode executar a célula pressionando \"SHIFT\" + \"ENTER\" ou clicando em \"Run Cell\" localizado na barra superior do bloco de notas.\n",
        "\n",
        "Frequentemente, especificaremos \"`(≈ X linhas de código)`\" nos comentários para informar sobre quanto código você precisa escrever. Isso é apenas uma estimativa aproximada, por isso não se sinta mal se o seu código for mais longo ou mais curto."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "usY7YE6y2rjY"
      },
      "source": [
        "### Exercício #1:\n",
        "\n",
        "Modifique a variável teste para `\" Alô Mundo \"` na célula abaixo para imprimir `Alô Mundo` e execute as duas células abaixo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "cpGEtmy-2rjZ"
      },
      "outputs": [],
      "source": [
        "# PARA VOCÊ FAZER:\n",
        "\n",
        "### COMEÇE AQUI ### (≈ 1 linha de código)\n",
        "teste = \"Alo Mundo\"\n",
        "### TERMINE AQUI ###"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "542GdDcd2rjc",
        "outputId": "0d45676d-2658-45a5-d683-60d70e112cca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "teste: Alo Mundo\n"
          ]
        }
      ],
      "source": [
        "print (\"teste: \" + teste)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yRusFMDf2rje"
      },
      "source": [
        "**Saída esperada**:\n",
        "\n",
        "    teste: Alô Mundo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vv3QeL932rje"
      },
      "source": [
        "**O que você precisa lembrar**:\n",
        "- Executar suas células usando SHIFT + ENTER (ou clicar em \"RUN\" na barra superior)\n",
        "- Escrever código nas áreas designadas usando apenas Python 3\n",
        "- Não modifique o código fora das áreas designadas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oWDMYIqq2rjf"
      },
      "source": [
        "## 1 - Construindo funções básicas com numpy ##\n",
        "\n",
        "Numpy é a principal biblioteca de funções para computação científica em Python. É mantido por uma grande comunidade (www.numpy.org). Neste exercício, você aprenderá várias funções de numpy, tais como, np.exp, np.log e np.reshape. Você precisará saber como usar essas funções para futuros trabalhos.\n",
        "\n",
        "### 1.1 - Função sigmoide ###\n",
        "\n",
        "A função sigmoide é baseada na função exponencial. Mas antes de usar a função exponencial da biblioteca numpy, `np.exp()`, você usará a função exponencial da bilbioteca, math `math.exp()`, para implementar a função sigmoide. Você verá então porque `np.exp()` é preferível a `math.exp()`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vk8OKoMX2rjf"
      },
      "source": [
        "### Exercício #2:\n",
        "\n",
        "Construa uma função que retorne a sigmoide de um número real `x`. Use `math.exp(x)` para a calcular a função exponencial.\n",
        "\n",
        "**Observação**: a função $  sigmoid(x) = \\frac{1} {1 + e ^ {- x}}  $ é também conhecida como função logística, sendo uma função não linear usada não só em redes neurais mas também em Machine Learning (Regressão Logística).\n",
        "\n",
        "Para se referir a uma função pertencente a um pacote específico, você pode chamá-la usando `package_name.function()`.\n",
        "\n",
        "Modifique e execute o código abaixo para criar e ver a função `basic_sigmoid()` com `math.exp()`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "-5Er-tMU2rjg"
      },
      "outputs": [],
      "source": [
        "# PARA VOCÊ FAZER: basic_sigmoid\n",
        "\n",
        "import math\n",
        "\n",
        "def basic_sigmoid(x):\n",
        "    \"\"\"\n",
        "    Calcula sigmoid de x.\n",
        "\n",
        "    Argumentos:\n",
        "    x -- A escalar\n",
        "\n",
        "    Retorna:\n",
        "    s -- sigmoid(x)\n",
        "    \"\"\"\n",
        "\n",
        "    ### COMEÇE AQUI ### (≈ 1 linha de código)\n",
        "    s = (1/(1+ math.exp(-x)))\n",
        "    ### TERMINE AQUI ###\n",
        "\n",
        "    return s"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k8RMud7t2rji",
        "outputId": "682375e5-0b64-422b-ac6c-5d935069c4d4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9525741268224334"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "basic_sigmoid(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HnJSkvDT2rjk"
      },
      "source": [
        "**Resultado esperado**:\n",
        "\n",
        "    0.9525741268224334"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qR9bO9K72rjk"
      },
      "source": [
        "Na verdade, raramente usamos a biblioteca \"matemática\" em redes neurais porque as entradas das funções são números reais. Em redes neurais usamos principalmente matrizes e vetores (tensores). É por isso que numpy é mais útil. Execute a célula abaxo e veja o que acontece."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "_QFg0ItN2rjl",
        "outputId": "5e13a04d-6ec6-48b5-fb72-6c1d3d272b06"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "bad operand type for unary -: 'list'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-f8d61ca34618>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m### Uma razão para usar \"numpy\" no lugar de \"math\" em redes neurais ###\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mbasic_sigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# você verá que essa função gera um erro, isso é causado porque x é um vetor.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-7-dc8b9f587d50>\u001b[0m in \u001b[0;36mbasic_sigmoid\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;31m### COMEÇE AQUI ### (≈ 1 linha de código)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0;31m### TERMINE AQUI ###\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: bad operand type for unary -: 'list'"
          ]
        }
      ],
      "source": [
        "### Uma razão para usar \"numpy\" no lugar de \"math\" em redes neurais ###\n",
        "x = [1, 2, 3]\n",
        "basic_sigmoid(x) # você verá que essa função gera um erro, isso é causado porque x é um vetor."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Ln3RqYI2rjn"
      },
      "source": [
        "De fato, se $ x = (x_1, x_2, ..., x_n)$ é um vetor linha, então $np.exp(x)$ aplica a função exponencial idependentemente a cada elemento do vetor $x$. A saída será então: $np.exp(x) = (e^{x_1}, e^{x_2}, ..., e^{x_n})$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GwpZatRU2rjo",
        "outputId": "c4877ba5-85ce-427f-b324-e783f45fbce7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 2.71828183  7.3890561  20.08553692]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np # com isso você pode acessar as funções do numpy escrevendo somente np.function() no lugar de numpy.function()\n",
        "\n",
        "# Exemplo de np.exp\n",
        "x = np.array([1, 2, 3])\n",
        "print(np.exp(x)) # resultado é (exp(1), exp(2), exp(3))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HvdUlLjk2rjr"
      },
      "source": [
        "### Exercício #3:\n",
        "\n",
        "Crie alguns tensores numpy e execute algumas operações com esses tensores usando as funções da biblioteca numpay.\n",
        "\n",
        "Se $x$ é um vetor **numpy**, então uma operação em Python, tal como, $s = x + 3$ or $s = \\frac{1}{x}$ irá produzir um vetor de saída $s$ do mesmo tamanho do vetor de entrada $x$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qd9iQ_0A2rjr",
        "scrolled": true,
        "outputId": "5cbcfb2e-c406-469b-b252-08207da108da"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "v + 3 =  [4 5 6]\n",
            "1/v =  [1.         0.5        0.33333333]\n",
            "umax =  -1\n",
            "vmin =  1\n",
            "uv =  -14\n",
            "uvi =  [-1 -4 -9]\n"
          ]
        }
      ],
      "source": [
        "# PARA VOCÊ FAZER: operações com vetores\n",
        "\"\"\"\n",
        "    Dados dois vetores u e v  calcule:\n",
        "    s1 = v + 3\n",
        "    s2 = 1/v\n",
        "    umax = valor maximo de u\n",
        "    vmin = valor mínimo de v\n",
        "    uv = produto escalar de u por v\n",
        "    uvi = produto elemento por elemento de v por u\n",
        "\"\"\"\n",
        "\n",
        "v = np.array([1, 2, 3])\n",
        "u = np.array([-1, -2, -3])\n",
        "\n",
        "### COMEÇE AQUI ### (≈ 6 linhas)\n",
        "s1 = v + 3\n",
        "s2 = 1/v\n",
        "umax = u.max()\n",
        "vmin = v.min()\n",
        "uv = np.dot(v,u)\n",
        "uvi = v*u\n",
        "### TERMINE AQUI ###\n",
        "\n",
        "print(\"v + 3 = \", s1)\n",
        "print(\"1/v = \", s2)\n",
        "print(\"umax = \", umax)\n",
        "print(\"vmin = \", vmin)\n",
        "print(\"uv = \", uv)\n",
        "print(\"uvi = \", uvi)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nQtP7ibR2rjv"
      },
      "source": [
        "**Resultado esperado:**\n",
        "\n",
        "    v + 3 = [4 5 6]\n",
        "    1/v = [1. 0.5 0.33333333]\n",
        "    umax = -1\n",
        "    vmin = 1\n",
        "    uv = -14\n",
        "    uvi = [-1 -4 -9]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "davltoYu2rjw"
      },
      "source": [
        "A qualquer momento que você precisar de mais informação sobre uma função do numpy, olhe na [documentação oficial](https://docs.scipy.org/doc/numpy-1.10.1/reference/generated/numpy.exp.html).\n",
        "\n",
        "Você pode também criar uma nova célula no notebook jupiter e escrever `np.exp?` (por exemplo) para conseguir acesso rápido à documentação."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KMI3FCkY2rjx"
      },
      "source": [
        "### Exercício #4:\n",
        "\n",
        "Implemente a função `sigmoid()` usando numpy.\n",
        "\n",
        "**Instruções**: $x$ pode ser um número real, um vetor, ou uma matriz. A estrutura de dados que se usa em numpy para representar esses tipos de dados (vetores, matrizes, tensores...) são chamados de \"numpy arrays\".\n",
        "\n",
        "$$ \\text{Para } x \\in \\mathbb{R}^n \\text{,     } sigmoid(x) = sigmoid\\begin{pmatrix}\n",
        "    x_1  \\\\\n",
        "    x_2  \\\\\n",
        "    ...  \\\\\n",
        "    x_n  \\\\\n",
        "\\end{pmatrix} = \\begin{pmatrix}\n",
        "    \\frac{1}{1+e^{-x_1}}  \\\\\n",
        "    \\frac{1}{1+e^{-x_2}}  \\\\\n",
        "    ...  \\\\\n",
        "    \\frac{1}{1+e^{-x_n}}  \\\\\n",
        "\\end{pmatrix} $$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "80-Pu5G02rjy"
      },
      "outputs": [],
      "source": [
        "# PARA VOCÊ FAZER: sigmoid\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "def sigmoid(x):\n",
        "    \"\"\"\n",
        "    Calcule a fnção sigmoid de x\n",
        "\n",
        "    Argumentos:\n",
        "    x -- Um escalar ou um numpy array de qualquer dimensão\n",
        "\n",
        "    Retorna:\n",
        "    s -- sigmoid(x)\n",
        "    \"\"\"\n",
        "\n",
        "    ### COMECE AQUI ### (≈ 1 linha)\n",
        "    s = (1/(1+ np.exp(-x)))\n",
        "    ### TERMINE AQUI ###\n",
        "\n",
        "    return s"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iZCGQtxR2rj0",
        "outputId": "dc0fe3e1-8ad6-4d7c-91a1-6f92baf607c3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.73105858, 0.88079708, 0.95257413])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "x = np.array([1, 2, 3])\n",
        "sigmoid(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WdWC4ho12rj2"
      },
      "source": [
        "**Saída esperada**:\n",
        "\n",
        "    array([ 0.73105858,  0.88079708,  0.95257413])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TV_PTTwQ2rj2"
      },
      "source": [
        "### 1.2 - Derivada da função sigmoide\n",
        "\n",
        "Como visto em aula, você precisa calcular derivadas para otimizar a função de custo usando a retro-propagação. Vamos codificar a derivada da função sigmoide."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4OPIZzNQ2rj3"
      },
      "source": [
        "### Exercício #5:\n",
        "\n",
        "Implemente a função `sigmoid_grad()` para calcular a derivada da função sigmóide em relação à sua entrada x.\n",
        "\n",
        "A fórmula é: $$sigmoid\\_derivative(x) = \\sigma'(x) = \\sigma(x) (1 - \\sigma(x))$$\n",
        "\n",
        "Você pode codificar essa função em duas etapas:\n",
        "1. Defina s como sendo a sigmoide de $x$. Use a sua função sigmoide.\n",
        "2. Calcule $\\sigma'(x) = s(1-s)$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "2V2T7_yx2rj3"
      },
      "outputs": [],
      "source": [
        "# PARA VOCÊ FAZER: sigmoid_derivative\n",
        "\n",
        "def sigmoid_derivative(x):\n",
        "    \"\"\"\n",
        "    Calcule a derivada da função sigmoide em relação à sua entrada.\n",
        "\n",
        "    Arguments:\n",
        "    x -- um escalar ou um tensor numpy\n",
        "\n",
        "    Return:\n",
        "    ds -- derivada da sigmoide\n",
        "    \"\"\"\n",
        "\n",
        "    ### COMECE AQUI ### (≈ 2 linhas)\n",
        "    s = (1/(1+ np.exp(-x)))\n",
        "    ds = s*(1-s)\n",
        "    ### TERMINE AQUI ###\n",
        "\n",
        "    return ds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oO_xLe6s2rj5",
        "outputId": "859f52c8-09b5-4c74-a95f-bee835bd5998"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sigmoid_derivative(x) = [0.19661193 0.10499359 0.04517666]\n"
          ]
        }
      ],
      "source": [
        "x = np.array([1, 2, 3])\n",
        "print (\"sigmoid_derivative(x) = \" + str(sigmoid_derivative(x)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hji_znC92rj7"
      },
      "source": [
        "**Saída esperada**:\n",
        "\n",
        "    sigmoid_derivative(x) = [ 0.19661193  0.10499359  0.04517666]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_SRQcF152rj7"
      },
      "source": [
        "### 1.3 - Alterando dimensões de tensores ###\n",
        "\n",
        "Duas funções comuns usadas em deep-learning são [np.shape()](https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.shape.html) e [np.reshape()](https://docs.scipy.org/doc/numpy/reference/generated/numpy.reshape.html).\n",
        "- `X.shape(X)` é usada para obter a dimensão de um tensor `X`.\n",
        "- `X.reshape(X)` é usada para alterar a dimensão de `X`.\n",
        "\n",
        "Por exemplo, uma imagem digital é representada por um tensor 3D de dimensões $(length, height, depth = 3)$. Contudo, quando se usa uma imagem como entrada de uma RNA ela em geral deve ser convertida para uma vetor de dimensão $(length*height*3, 1)$. Em outras palavras, deve-se desenrolar ou alterar a dimensão do tensor 3D para um vetor 1D.\n",
        "\n",
        "<img src=\"image2vector_kiank.png\" style=\"width:500px;height:300;\">\n",
        "(Andrew Ng, deeplearning.ai)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZhAlO_iD2rj8"
      },
      "source": [
        "### Exercício #6:\n",
        "\n",
        "Implemente uma função `image2vector()` que recebe como entrada uma imagem (tensor) de dimensão (length, height, 3) e retorna um vetor de dimensão (length\\*height\\*3, 1). Por exemplo, se quiser redimensionar um tensor v de dimensão (a, b, c) para um vetor\n",
        "de dimensão (a*b,c) deve-se fazer:\n",
        "\n",
        "``` python\n",
        "v = v.reshape((v.shape[0]*v.shape[1], v.shape[2])) # v.shape[0] = a ; v.shape[1] = b ; v.shape[2] = c\n",
        "```\n",
        "\n",
        "**Observação:** nunca codifique as dimensões de uma imagem como uma constante. No lugar obtenha as dimensões da imagem com a função `image.shape[0]`, ou `image.shape[1]`, etc."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "Rhs53fS_2rj8"
      },
      "outputs": [],
      "source": [
        "# PARA VOCÊ FAZER: image2vector\n",
        "def image2vector(image):\n",
        "    \"\"\"\n",
        "    Argumento:\n",
        "    image -- um tensor numpy de dimensão (length, height, depth)\n",
        "\n",
        "    Retorna:\n",
        "    v -- um vetor de dimensão (length*height*depth, 1)\n",
        "    \"\"\"\n",
        "\n",
        "    ### COMECE AQUI ### (≈ 1 linha)\n",
        "    v = image.reshape((image.shape[0]*image.shape[1]*image.shape[2], 1))\n",
        "    ### TERMINE AQUI ###\n",
        "\n",
        "    return v"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YH2YY0u_2rj-",
        "outputId": "5b4f7708-4617-45a1-8b5a-7c1b06ff65d7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "image2vector(image) = [[0.67826139]\n",
            " [0.29380381]\n",
            " [0.90714982]\n",
            " [0.52835647]\n",
            " [0.4215251 ]\n",
            " [0.45017551]\n",
            " [0.92814219]\n",
            " [0.96677647]\n",
            " [0.85304703]\n",
            " [0.52351845]\n",
            " [0.19981397]\n",
            " [0.27417313]\n",
            " [0.60659855]\n",
            " [0.00533165]\n",
            " [0.10820313]\n",
            " [0.49978937]\n",
            " [0.34144279]\n",
            " [0.94630077]]\n"
          ]
        }
      ],
      "source": [
        "# Exemplo de tensor 3 por 3 by por 2, typicamente uma imagem tem dimensão (num_px_x, num_px_y,3) onde o terceiro eixo representa\n",
        "# os planos de cor RGB\n",
        "image = np.array([[[ 0.67826139,  0.29380381],\n",
        "        [ 0.90714982,  0.52835647],\n",
        "        [ 0.4215251 ,  0.45017551]],\n",
        "\n",
        "       [[ 0.92814219,  0.96677647],\n",
        "        [ 0.85304703,  0.52351845],\n",
        "        [ 0.19981397,  0.27417313]],\n",
        "\n",
        "       [[ 0.60659855,  0.00533165],\n",
        "        [ 0.10820313,  0.49978937],\n",
        "        [ 0.34144279,  0.94630077]]])\n",
        "\n",
        "print (\"image2vector(image) = \" + str(image2vector(image)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZWaWPBCs2rkB"
      },
      "source": [
        "**Saída esperada:**\n",
        "\n",
        "    image2vector(image) = [[ 0.67826139]\n",
        "     [ 0.29380381]\n",
        "     [ 0.90714982]\n",
        "     [ 0.52835647]\n",
        "     [ 0.4215251 ]\n",
        "     [ 0.45017551]\n",
        "     [ 0.92814219]\n",
        "     [ 0.96677647]\n",
        "     [ 0.85304703]\n",
        "     [ 0.52351845]\n",
        "     [ 0.19981397]\n",
        "     [ 0.27417313]\n",
        "     [ 0.60659855]\n",
        "     [ 0.00533165]\n",
        "     [ 0.10820313]\n",
        "     [ 0.49978937]\n",
        "     [ 0.34144279]\n",
        "     [ 0.94630077]]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xkViiitl2rkB"
      },
      "source": [
        "### 1.4 - Normalização de vetores\n",
        "\n",
        "Uma operação comum em Aprendizado de Máquina é normalizar os dados. Em geral a normalização dos dados gera um desemepnho melhor da RNA em razão do gradiente descendente convergir mais rápido com dados normalizados. Nessa tarefa, vamos normalizar um vetor linha dividindo-o pela sua norma 2, ou seja:\n",
        "\n",
        "$$ \\frac{x}{\\| x\\|} $$\n",
        "\n",
        "Por exemplo, se:\n",
        "\n",
        "$$x = \\begin{bmatrix}\n",
        "    0 & 3 & 4 \\\\\n",
        "    2 & 6 & 4 \\\\\n",
        "\\end{bmatrix}$$\n",
        "\n",
        "então essa operação pode ser realizada pela seguinte função Numpy:\n",
        "\n",
        "$$\\| x\\| = np.linalg.norm(x, axis = 1, keepdims = True) = \\begin{bmatrix}\n",
        "    5 \\\\\n",
        "    \\sqrt{56} \\\\\n",
        "\\end{bmatrix}$$\n",
        "\n",
        "e por:\n",
        "\n",
        "$$ x\\_normalized = \\frac{x}{\\| x\\|} = \\begin{bmatrix}\n",
        "    0 & \\frac{3}{5} & \\frac{4}{5} \\\\\n",
        "    \\frac{2}{\\sqrt{56}} & \\frac{6}{\\sqrt{56}} & \\frac{4}{\\sqrt{56}} \\\\\n",
        "\\end{bmatrix}$$\n",
        "\n",
        "Note que é possível dividir matrizes de dimensões diferentes sem problemas, pois o \"broadcasting\" faz isso automaticamente.\n",
        "\n",
        "**Observação:** Verifique na documentação da biblioteca numpy o que significa os argumentos `axis` e `keepdims` na função `linalg.norm`.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q3M8eJOa2rkC"
      },
      "source": [
        "### Exercício #7:\n",
        "\n",
        "Implemente a função `normalizeRows()` para normalizar as linhas de uma matriz. Após aplicar essa função em uma matriz cada linha deve ser um vetor com norma 2 igual a 1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "id": "61QP80DW2rkD"
      },
      "outputs": [],
      "source": [
        "# PARA VOCÊ FAZER: normalizeRows\n",
        "\n",
        "def normalizeRows(x):\n",
        "    \"\"\"\n",
        "    Implemente uma função que normaliza cada linha de uma matriz de forma que tenham norma unitária.\n",
        "\n",
        "    Argumento:\n",
        "    x -- Uma matriz numpy de dimensões (n, m)\n",
        "\n",
        "    Retorna:\n",
        "    x -- A matriz normalizada (linha por linha).\n",
        "    \"\"\"\n",
        "\n",
        "    ### COMECE AQUI ### (≈ 2 linHAS)\n",
        "    # Calcule x_norm como sendo a norma 2 de x. Use np.linalg.norm(..., ord = 2, axis = ..., keepdims = True)\n",
        "    x_norm = np.linalg.norm(x, ord = 2,axis = 1,keepdims=True)\n",
        "    x = x / x_norm\n",
        "    ### END CODE HERE ###\n",
        "\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jW17813-2rkG",
        "outputId": "33923084-70dc-46ce-ea2f-b22647e5895f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matriz normalizada = [[0.         0.6        0.8       ]\n",
            " [0.13736056 0.82416338 0.54944226]]\n"
          ]
        }
      ],
      "source": [
        "x = np.array([\n",
        "    [0, 3, 4],\n",
        "    [1, 6, 4]])\n",
        "print(\"Matriz normalizada = \" + str(normalizeRows(x)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "efnfarxB2rkJ"
      },
      "source": [
        "**Saída esperada:**\n",
        "\n",
        "    Matriz normalizada = [[ 0.          0.6         0.8       ]\n",
        "     [ 0.13736056  0.82416338  0.54944226]]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O3_G6CcE2rkJ"
      },
      "source": [
        "**Observação:**\n",
        "\n",
        "Tente na função `normalizeRows()` imprimir as dimensões de `x_norm` e `x` e executar novamente. Você verá que eles tem dimensões diferentes. Isso é óbvio dado que `x_norm` é um único valor para cada linha de `x`. Portanto a dimensão de `x_norm` é igual ao número de linhas de `x`, mas é somente um vetor coluna. A divisão de `x` por `x_norm` só é possível pelo \"broadcast\" (ajuste) feito automaticamente pelo Numpy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GgzkQHJ52rkK"
      },
      "source": [
        "### 1.5 - Broadcasting e a função softmax ####\n",
        "Como vimos na teoria um conceito muito importante em Numpy é o ajuste automático de dimensões (\"broadcasting\"). O \"broadcasting\" é muito útil para realizar operações matemáticas entre tensores de dimensões diferentes. Para ver todos os detalhes do conceito de \"broadcasting\", você pode ver a documentação oficial do broadcasting  [broadcasting documentation](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tcHinqqC2rkL"
      },
      "source": [
        "### Exercício #8:\n",
        "\n",
        "Implemente uma função chamada `softmax` usando numpy. Você pode considerar que a função `softmax` é uma função que normaliza as linhas da exponencial de cada elemento de uma matriz.\n",
        "\n",
        "**Instrucões:**\n",
        "- $ \\text{para um vetor } x \\in \\mathbb{R}^{1\\times n} \\text{,     } softmax(x) = softmax(\\begin{bmatrix}\n",
        "    x_1  &&\n",
        "    x_2 &&\n",
        "    ...  &&\n",
        "    x_n  \n",
        "\\end{bmatrix}) = \\begin{bmatrix}\n",
        "     \\frac{e^{x_1}}{\\sum_{j}e^{x_j}}  &&\n",
        "    \\frac{e^{x_2}}{\\sum_{j}e^{x_j}}  &&\n",
        "    ...  &&\n",
        "    \\frac{e^{x_n}}{\\sum_{j}e^{x_j}}\n",
        "\\end{bmatrix}$\n",
        "\n",
        "- $\\text{para uma matrix } x \\in \\mathbb{R}^{m \\times n} \\text{: }$  $$softmax(x) = softmax\\begin{bmatrix}\n",
        "    x_{11} & x_{12} & x_{13} & \\dots  & x_{1n} \\\\\n",
        "    x_{21} & x_{22} & x_{23} & \\dots  & x_{2n} \\\\\n",
        "    \\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
        "    x_{m1} & x_{m2} & x_{m3} & \\dots  & x_{mn}\n",
        "\\end{bmatrix} = \\begin{bmatrix}\n",
        "    \\frac{e^{x_{11}}}{\\sum_{j}e^{x_{1j}}} & \\frac{e^{x_{12}}}{\\sum_{j}e^{x_{1j}}} & \\frac{e^{x_{13}}}{\\sum_{j}e^{x_{1j}}} & \\dots  & \\frac{e^{x_{1n}}}{\\sum_{j}e^{x_{1j}}} \\\\\n",
        "    \\frac{e^{x_{21}}}{\\sum_{j}e^{x_{2j}}} & \\frac{e^{x_{22}}}{\\sum_{j}e^{x_{2j}}} & \\frac{e^{x_{23}}}{\\sum_{j}e^{x_{2j}}} & \\dots  & \\frac{e^{x_{2n}}}{\\sum_{j}e^{x_{2j}}} \\\\\n",
        "    \\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
        "    \\frac{e^{x_{m1}}}{\\sum_{j}e^{x_{mj}}} & \\frac{e^{x_{m2}}}{\\sum_{j}e^{x_{mj}}} & \\frac{e^{x_{m3}}}{\\sum_{j}e^{x_{mj}}} & \\dots  & \\frac{e^{x_{mn}}}{\\sum_{j}e^{x_{mj}}}\n",
        "\\end{bmatrix} = \\begin{pmatrix}\n",
        "    softmax\\text{(primeira linha de x)}  \\\\\n",
        "    softmax\\text{(segunda linha de x)} \\\\\n",
        "    ...  \\\\\n",
        "    softmax\\text{(última linha de x)} \\\\\n",
        "\\end{pmatrix}$$\n",
        "\n",
        "- $\\text{para calcular a somatoria dos elementos de um vetor pode ser usada a função np.sum() da seguinte forma:}$ $\\| x\\| = np.sum(x, axis = 1, keepdims = True)$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {
        "id": "_3gaFv2Z2rkL"
      },
      "outputs": [],
      "source": [
        "# PARA VOCÊ FAZER: softmax\n",
        "\n",
        "def softmax(x):\n",
        "    \"\"\"Calcule a função softmax para cada linha da matriz de entrada x.\n",
        "\n",
        "    Seu programa deve funcionar para um vetor linha e também para matrizes de dimensões genéricas (n, m).\n",
        "\n",
        "    Argumento:\n",
        "    x -- Uma matriz numpy de dimensões (n,m)\n",
        "\n",
        "    Retorna:\n",
        "    s -- Uma matriz numpay de dimensões A numpy matrix equal to the softmax of x, of shape (n,m)\n",
        "    \"\"\"\n",
        "\n",
        "    ### COMECE AQUI ### (≈ 3 lINHAS)\n",
        "    x_exp = np.exp(x)\n",
        "    x_sum = np.sum(x_exp,axis = 1,keepdims=True)\n",
        "    s = x_exp/x_sum\n",
        "    ### TERMINE AQUI ###\n",
        "\n",
        "    return s"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0QOgP85J2rkO",
        "outputId": "cc5b8e3b-2df4-4f16-8d80-469325519b16"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "softmax(x) = [[9.80897665e-01 8.94462891e-04 1.79657674e-02 1.21052389e-04\n",
            "  1.21052389e-04]\n",
            " [8.78679856e-01 1.18916387e-01 8.01252314e-04 8.01252314e-04\n",
            "  8.01252314e-04]]\n"
          ]
        }
      ],
      "source": [
        "x = np.array([\n",
        "    [9, 2, 5, 0, 0],\n",
        "    [7, 5, 0, 0 ,0]])\n",
        "print(\"softmax(x) = \" + str(softmax(x)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qrKjYGk92rkR"
      },
      "source": [
        "**Saída esperada:**\n",
        "\n",
        "    softmax(x) = [[  9.80897665e-01   8.94462891e-04   1.79657674e-02   1.21052389e-04\n",
        "      1.21052389e-04]\n",
        "     [8.78679856e-01   1.18916387e-01   8.01252314e-04   8.01252314e-04\n",
        "      8.01252314e-04]]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O2KgJzrt2rkS"
      },
      "source": [
        "**Nota**: Se você imprimir as dimensões de `x_exp`, `x_sum` e `s` acima, você verá que `x_sum` tem dimensão (2,1) enquanto que `x_exp` e `s` tem dimensões (2,5). O cálculo **x_exp/x_sum** funciona em razão do \"broadcasting\" em Python."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g2FCmRSY2rkS"
      },
      "source": [
        "<font color='blue'>\n",
        "    \n",
        "**O que é preciso lembrar:**\n",
        "\n",
        "- `np.exp(x)` funciona para qualquer tensor numpy e aplica a função exponencial em todos os elementos do tensor;\n",
        "- a função `sigmoide`, sua derivada e a função `image2vector` são muito usadas em deep-learning;\n",
        "- `np.reshape` é amplamente utilizada;\n",
        "- manter as dimensões dos tensores corretas é muito importante;\n",
        "- numpy possui muitas funcções úteis;\n",
        "- broadcasting é extremamente útil."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "nkE-DdKQ2rkT"
      },
      "source": [
        "## 2 - Vectorização"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l2jo9P4R2rkU"
      },
      "source": [
        "Como visto na teoria, em deep-learning lidamos com conjunto de dados extremamente grandes. Portanto, as funções devem ser otimizadas para não criar um gargalo computacional e demorar muito para realizar os cálculos. Para tornar um programa eficiente devemos usar vetorização dos cálculos. Por exemplo, vamos ver a diferencça entre as seguintes implementações das funções produto escalar (produto interno), produto externo e produto de elemento por elemento de dois vetores implementadas classicamente com loops e de forma vetorizada."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QnFtI3Q42rkV",
        "outputId": "1034c797-abf0-469b-8f7c-2bc8de6d476a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "produto escalar = 278\n",
            "produto de dois vetores = [[81. 18. 18. 81.  0. 81. 18. 45.  0.  0. 81. 18. 45.  0.  0.]\n",
            " [18.  4.  4. 18.  0. 18.  4. 10.  0.  0. 18.  4. 10.  0.  0.]\n",
            " [45. 10. 10. 45.  0. 45. 10. 25.  0.  0. 45. 10. 25.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
            " [63. 14. 14. 63.  0. 63. 14. 35.  0.  0. 63. 14. 35.  0.  0.]\n",
            " [45. 10. 10. 45.  0. 45. 10. 25.  0.  0. 45. 10. 25.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
            " [81. 18. 18. 81.  0. 81. 18. 45.  0.  0. 81. 18. 45.  0.  0.]\n",
            " [18.  4.  4. 18.  0. 18.  4. 10.  0.  0. 18.  4. 10.  0.  0.]\n",
            " [45. 10. 10. 45.  0. 45. 10. 25.  0.  0. 45. 10. 25.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]]\n",
            "multiplicação elemento-por-elemento = [81.  4. 10.  0.  0. 63. 10.  0.  0.  0. 81.  4. 25.  0.  0.]\n",
            "produto matriz-vetor = [19.15825122 22.35571409 24.49820791]\n",
            " ----- Tempo de computação = 6.8942560000024855ms\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "\n",
        "x1 = [9, 2, 5, 0, 0, 7, 5, 0, 0, 0, 9, 2, 5, 0, 0]\n",
        "x2 = [9, 2, 2, 9, 0, 9, 2, 5, 0, 0, 9, 2, 5, 0, 0]\n",
        "\n",
        "### IMPLEMENTAÇÃO CLÁSSICA DO PRODUTO ESCALAR ENTRE DOIS VETORES ###\n",
        "tic = time.process_time()\n",
        "dot = 0\n",
        "for i in range(len(x1)):\n",
        "    dot+= x1[i]*x2[i]\n",
        "print (\"produto escalar = \" + str(dot))\n",
        "\n",
        "### IMPLEMENTAÇÃO CLÁSSICA DO PRODUTO EXTERNO ENTRE DOIS VETORES ###\n",
        "outer = np.zeros((len(x1),len(x2))) # primeiramente criamos uma matriz de zeros com dimensão len(x1) x len(x2)\n",
        "for i in range(len(x1)):\n",
        "    for j in range(len(x2)):\n",
        "        outer[i,j] = x1[i]*x2[j]\n",
        "#toc = time.process_time()\n",
        "print (\"produto de dois vetores = \" + str(outer))\n",
        "\n",
        "### IMPLEMENTAÇÃO CLÁSSICA DO PRODUTO DE DOIS VETORES ELEMENTO POR ELEMENTO ###\n",
        "mul = np.zeros(len(x1))\n",
        "for i in range(len(x1)):\n",
        "    mul[i] = x1[i]*x2[i]\n",
        "#toc = time.process_time()\n",
        "print (\"multiplicação elemento-por-elemento = \" + str(mul))\n",
        "\n",
        "### IMPLEMENTAÇÃO CLÁSSICA DO PRODUTO DE UMA MATRIZ POR UM VETOR ###\n",
        "np.random.seed(3)\n",
        "W = np.random.rand(3,len(x1)) # Vetor numpy com números aletórios de dimensão 3 x len(x1)\n",
        "gdot = np.zeros(W.shape[0])\n",
        "for i in range(W.shape[0]):\n",
        "    for j in range(len(x1)):\n",
        "        gdot[i] += W[i,j]*x1[j]\n",
        "toc = time.process_time()\n",
        "print (\"produto matriz-vetor = \" + str(gdot) + \"\\n ----- Tempo de computação = \" + str(1000*(toc - tic)) + \"ms\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ApKwG1Jg2rkW"
      },
      "source": [
        "### Exercício #9:\n",
        "\n",
        "Implemente os cálculos da célula anterior mas de forma vetorizada. Para fazer isso você pode usar as seguintes funções da biblioteca numpy: `dot`, `outer`, `multiply` e o operador `*`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T7kLk-5W2rkX",
        "outputId": "03cb95e4-8bba-4777-b5e5-bcfce8765c87"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "produto escalar = 278\n",
            "produto de dois vetores = [[81 18 18 81  0 81 18 45  0  0 81 18 45  0  0]\n",
            " [18  4  4 18  0 18  4 10  0  0 18  4 10  0  0]\n",
            " [45 10 10 45  0 45 10 25  0  0 45 10 25  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [63 14 14 63  0 63 14 35  0  0 63 14 35  0  0]\n",
            " [45 10 10 45  0 45 10 25  0  0 45 10 25  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [81 18 18 81  0 81 18 45  0  0 81 18 45  0  0]\n",
            " [18  4  4 18  0 18  4 10  0  0 18  4 10  0  0]\n",
            " [45 10 10 45  0 45 10 25  0  0 45 10 25  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]]\n",
            "produto elemento-por-elemento = [81  4 10  0  0 63 10  0  0  0 81  4 25  0  0]\n",
            " produto matriz-vetor = [19.15825122 22.35571409 24.49820791]\n",
            " ----- Computation time = 1.561487000000028ms\n"
          ]
        }
      ],
      "source": [
        "# PARA VOCÊ FAZER: vetorização\n",
        "\n",
        "x1 = np.array([9, 2, 5, 0, 0, 7, 5, 0, 0, 0, 9, 2, 5, 0, 0])\n",
        "x2 = np.array([9, 2, 2, 9, 0, 9, 2, 5, 0, 0, 9, 2, 5, 0, 0])\n",
        "\n",
        "tic = time.process_time()\n",
        "\n",
        "### PRODUTO ESCALAR VEOTRIZADO (x1 por x2) ###\n",
        "### COMECE AQUI ### (≈ 1 lINHA)\n",
        "dotv1 = np.dot(x1,x2)\n",
        "### TERMINE AQUI ###\n",
        "print (\"produto escalar = \" + str(dotv1))\n",
        "\n",
        "### PRODUTO MATRICIAL DE DOIS VETORES VECTORIZADO (x1 por x2) ###\n",
        "### COMECE AQUI ### (≈ 1 lINHA)\n",
        "outerv = np.outer(x1,x2)\n",
        "### TERMINE AQUI ###\n",
        "print (\"produto de dois vetores = \" + str(outerv))\n",
        "\n",
        "### PRODUTO DE DOIS VETORES ELEMENTO-POR-ELEMENTO VECTORIZADO (x1 por x2) ###\n",
        "### COMECE AQUI ### (≈ 1 lINHA)\n",
        "mulv = np.multiply(x1,x2)\n",
        "### TERMINE AQUI ###\n",
        "print (\"produto elemento-por-elemento = \" + str(mulv))\n",
        "\n",
        "### PRODUTO MATRIX-VETOR VETORIZADO (W por x1) ###\n",
        "### COMECE AQUI ### (≈ 1 lINHA)\n",
        "dotv2 = np.dot(W,x1)\n",
        "### TERMINE AQUI ###\n",
        "\n",
        "toc = time.process_time()\n",
        "print (\" produto matriz-vetor = \" + str(dotv2) + \"\\n ----- Computation time = \" + str(1000*(toc - tic)) + \"ms\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jkK83vPU2rkZ"
      },
      "source": [
        "**Saída esperada**:\n",
        "\n",
        "    produto escalar = 278\n",
        "    produto de dois vetores = [[81 18 18 81  0 81 18 45  0  0 81 18 45  0  0]\n",
        "     [18  4  4 18  0 18  4 10  0  0 18  4 10  0  0]\n",
        "     [45 10 10 45  0 45 10 25  0  0 45 10 25  0  0]\n",
        "     [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
        "     [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
        "     [63 14 14 63  0 63 14 35  0  0 63 14 35  0  0]\n",
        "     [45 10 10 45  0 45 10 25  0  0 45 10 25  0  0]\n",
        "     [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
        "     [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
        "     [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
        "     [81 18 18 81  0 81 18 45  0  0 81 18 45  0  0]\n",
        "     [18  4  4 18  0 18  4 10  0  0 18  4 10  0  0]\n",
        "     [45 10 10 45  0 45 10 25  0  0 45 10 25  0  0]\n",
        "     [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
        "     [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]]\n",
        "    produto elemento-por-elemento = [81  4 10  0  0 63 10  0  0  0 81  4 25  0  0]\n",
        "     produto matriz-vetor = [19.15825122 22.35571409 24.49820791]\n",
        "     ----- Computation time = 0.0ms"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ragF3LP42rkZ"
      },
      "source": [
        "Como se pode ver, a implementação vetorizada é muito mais simples e mais eficiente. Para tensores vetores/matrizes maiores a diferença de tempo computacional é ainda maior.\n",
        "\n",
        "**Note** que a função `np.dot()` realiza uma multiplicação entre matriz-matriz ou matriz-vetor, ou ainda entre quaisquer tensores desde que as dimensões sejam compatíveis. A função `np.multiply()` e o operador `*` realizam multiplicação elemento-por-elemento."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zoXZLM_D2rkc"
      },
      "source": [
        "### 2.1 - Implementação de funções de erro, ou de perda\n",
        "\n",
        "Como visto em aula, funções de erro (ou de perda) são utilizadas em deep-learning para calcular o erro entre a saída esperada e a saída calculada pela rede.\n",
        "\n",
        "Essas funções são usadas para avaliar a RNA. Quanto maior o erro, pior são as previsões ($ \\hat{y} $) em relação aos valores reais ($y$)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uePziHNr2rke"
      },
      "source": [
        "### Exercício #10:\n",
        "\n",
        "Implemente uma versão vetorizada da função de erro absoluto:\n",
        "\n",
        "$$\\begin{align*} & L_1(\\hat{y}, y) = \\sum_{i=1}^m|y^{(i)} - \\hat{y}^{(i)}| \\end{align*}$$\n",
        "\n",
        "Utilize as funções numpy `np.sum(x)` (soma de todos os elementos do vetor $x$) e `np.abs(x)` (valor absoluto dos elementos do vetor $x$)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "metadata": {
        "id": "Fm9UKejQ2rkf"
      },
      "outputs": [],
      "source": [
        "# PARA VOCÊ FAZER: L1\n",
        "\n",
        "def L1(yhat, y):\n",
        "    \"\"\"\n",
        "    ArgumentOs:\n",
        "    yhat -- vetor de dimensão m (valores previstos)\n",
        "    y -- vetor de dimensão m (valores reais)\n",
        "\n",
        "    Retorna:\n",
        "    loss -- valor da função de erro L1\n",
        "    \"\"\"\n",
        "\n",
        "    ### COMEÇE AQUI ### (≈ 1 linha)\n",
        "    loss = np.sum(np.abs(y-yhat))\n",
        "    ### TERMINE AQUI ###\n",
        "\n",
        "    return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0rHAx9QT2rkh",
        "outputId": "5badf3e7-d8e8-47ec-c2f0-5921fbb02c11"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "L1 = 1.1\n"
          ]
        }
      ],
      "source": [
        "yhat = np.array([.9, 0.2, 0.1, .4, .9])\n",
        "y = np.array([1, 0, 0, 1, 1])\n",
        "print(\"L1 = \" + str(L1(yhat,y)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pnove8Xg2rki"
      },
      "source": [
        "**Saída esperada:**\n",
        "\n",
        "    L1 = 1.1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6nzYmvEi2rkj"
      },
      "source": [
        "### Exercício #11:\n",
        "\n",
        "Implemente uma versão vetorizada da função de erro quadrático:\n",
        "\n",
        "$$\\begin{align*} & L_2(\\hat{y},y) = \\sum_{i=0}^m(y^{(i)} - \\hat{y}^{(i)})^2 \\end{align*}$$\n",
        "\n",
        "**Observação:** Existem diversas formas de implementar essa função, mas talvez a forma mais fácil é usando a função numpy `np.dot`. Relembrando que, se $x = [x_1, x_2, ..., x_n]$, então `np.dot(x,x)` = $\\sum_{j=1}^n x_j^{2}$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "metadata": {
        "id": "O8Su0lma2rkj"
      },
      "outputs": [],
      "source": [
        "# PARA VOCÊ FAZER: FUNÇÃO L2\n",
        "\n",
        "def L2(yhat, y):\n",
        "    \"\"\"\n",
        "    Argumentos:\n",
        "    yhat -- vetor de dimensão mx1 (valores previstos)\n",
        "    y -- vetor de dimensão mx1 (valores reais)\n",
        "\n",
        "    Retorna:\n",
        "    loss -- o valor da função de erro L2\n",
        "    \"\"\"\n",
        "\n",
        "    ### COMEÇE AQUI ### (≈ 1 linha)\n",
        "    loss = np.sum(np.dot(y-yhat,y-yhat))\n",
        "    ### TERMINE AQUI ###\n",
        "\n",
        "    return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jZSRPEw82rkl",
        "outputId": "08ab3426-8016-47bb-f834-07e6ea4baad7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "L2 = 0.43\n"
          ]
        }
      ],
      "source": [
        "yhat = np.array([.9, 0.2, 0.1, .4, .9])\n",
        "y = np.array([1, 0, 0, 1, 1])\n",
        "print(\"L2 = \" + str(L2(yhat,y)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ef9xyNE_2rkm"
      },
      "source": [
        "**Saída esperada:**\n",
        "\n",
        "    L2 = 0.43"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sJQyL0URPPGn"
      },
      "source": [
        "## 3 - Neurônio\n",
        "\n",
        "Na Figura abaixo é apresentado um neurônio com 3 entradas.\n",
        "\n",
        "<img src=\"neuronio.png\" style=\"width:300px;height:200;\">\n",
        "\n",
        "As equações que descrevem o funcionamento de um neurônio foram vistas em aula e são as seguintes:\n",
        "\n",
        "  $$z = \\mathbf{Wx} + b$$\n",
        "\n",
        "  $$a = g(z)$$\n",
        "\n",
        "onde:\n",
        "- $z$ = estado do neurônio\n",
        "- $\\mathbf{W}$ = matriz de pesos das ligações dos neurônios de dimensão (1, nx)\n",
        "- $\\mathbf{x}$ = vetor de entradas do neurônio de dimensão (nx, 1)\n",
        "- $b$ = viés do neurônio\n",
        "- $a$ = ativação do neurônio\n",
        "- $g()$ = função de ativação do neurônio."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HXE1oz1gPPGn"
      },
      "source": [
        "### Exercício #12:\n",
        "\n",
        "Na célula abaixo defina uma função que implementa uma versão vetorizada para um único exemplo do funcionamento de um neurônio. Utilize a função `sigmoid(x)` feita no exercício #4. Observe que nessa função os parâmetros do neurônio ($\\mathbf{W}$ e $b$) são passados em um dicionário. Passar parâmetros para funções em dicionários simplifica o código quando temos muitos parâmetros, tal como é o caso de uma RNA de várias camadas.\n",
        "\n",
        "Para criar um dicionário de parametros usa-se, por exemplo, `parameters = {'W': w, 'b': b}`. Para recuperar os parâmetros do dicionário parameters você deve usar `parameters[\"..\"]`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 132,
      "metadata": {
        "id": "AMpxwJ0NPPGo"
      },
      "outputs": [],
      "source": [
        "# PARA VOCÊ FAZER: FUNÇÃO neuronio\n",
        "\n",
        "def neuronio(x, parameters):\n",
        "    \"\"\"\n",
        "    Argumentos:\n",
        "    x = vetor de entradas de dimensão (1, nx)\n",
        "    parameters = dicionário com parâmetros do neurônio contendo o vetor de pesos W de dimensão (1, nx) e o viés b\n",
        "\n",
        "    Retorna:\n",
        "    a = ativação do neurônio\n",
        "    \"\"\"\n",
        "\n",
        "    ### COMEÇE AQUI ### (≈ 2 linhas)\n",
        "    # Recupere o vetor de pesos W e o viés b do dicionário par\n",
        "    w = parameters['W']\n",
        "    b = parameters['b']\n",
        "    ### TERMINE AQUI ###\n",
        "\n",
        "    ### COMEÇE AQUI ### (≈ 2 linhas)\n",
        "    # Calcula a saída do neurônio tendo a sua entrada (x) e os seus parâmetros (W e b)\n",
        "    z = np.dot(w,x) + b\n",
        "    a = sigmoid(z)\n",
        "    ### TERMINE AQUI ###\n",
        "\n",
        "    return a"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 133,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5cTlr48qPPGo",
        "outputId": "75da8fa2-b423-455c-bddb-e2477326613e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ativação do neurônio= [[0.92368354]]\n"
          ]
        }
      ],
      "source": [
        "np.random.seed(13)\n",
        "x = np.random.random((5,1))\n",
        "w = np.random.random((1,5))\n",
        "b = np.random.random((1))\n",
        "parameters = {'W': w, 'b': b}\n",
        "\n",
        "a = neuronio(x,parameters)\n",
        "print('Ativação do neurônio=', a)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TnXXDl1XPPGo"
      },
      "source": [
        "**Saída esperada:**\n",
        "    \n",
        "    Ativação do neurônio= [[0.92368354]]    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PUHJIk8l2rkn"
      },
      "source": [
        "<font color='blue'>\n",
        "\n",
        "**O que deve ser lembrado:**\n",
        "\n",
        "- Vectorização é muito importante em deep-learning. Ela fornece eficiência computacional, simplicidade e clareza;\n",
        "- Algumas funções de erro bastante utilizadas;\n",
        "- Familiarização com muitas funções numpy, tais como, np.dot, np.sum, np.multiply, np.maximum etc;\n",
        "- Uso de dicionários facilita passar arqumentos para funções."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "coursera": {
      "course_slug": "neural-networks-deep-learning",
      "graded_item_id": "XHpfv",
      "launcher_item_id": "Zh0CU"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}